### MI300X vs H100 vs H200 벤치마크 1부: 학습 – 여전히 강력한 CUDA 생태계

##### 요점정리: 학습 성능, 사용자 경험, 사용성, Nvidia, AMD, GEMM, 어텐션(Attention), 네트워킹, 인피니밴드(InfiniBand), 스펙트럼-X(Spectrum-X) 이더넷, RoCEv2 이더넷, SHARP, 총 소유 비용


### 1. 소개 ###

SemiAnalysis는 MI300X의 실제 성능을 검증하기 위해 5개월간의 조사를 진행해왔다. 이론적으로 MI300X는 사양 및 총 소유 비용(TCO) 측면에서 Nvidia의 H100 및 H200에 비해 큰 장점을 가져야 한다. 그러나 아래에 나열된 사양은 실제 환경에서 기대할 수 있는 성능을 제대로 나타나지 않는다. 만약 AMD가 이 메모리를 통해 광고된 성능을 제공할 수 있다면, 시장에서 매우 강력한 경쟁자가 될 수 있을 것이다. 

[Source: SemiAnalysis, Nvidia, AMD]

오늘 우리는 MI300X, H100, H200에 대한 독립적인 분석과 학습 중심 벤치마킹을 진행한 5개월간의 여정을 이야기하려고 한다. 이 과정에서 우리는 NVIDIA와 AMD 양쪽과 소통하며 작업을 진행한다. 우리가 실행한 다양한 저수준 벤치마크에 대한 상세한 개요를 제공할 예정이며, 요약은 목차에서 확인할 수 있다. 또한, NVIDIA와 AMD GPU의 총 소유 비용(TCO)을 비교하고 성능을 포함한 여러 요소를 고려할 것이다. 우리는 궁극적으로 AMD가 경쟁력을 갖추기 위해 해야 할 일과, 5개월 동안 버그를 제출하고 수정하며 확인한 AMD 소프트웨어 문제를 어떻게 해결해야 할지에 대한 종합적인 공공 권고안을 공개적으로 제공할 것이다. 문제는 단순히 소프트웨어가 미숙하다는 점만이 아니라, AMD의 소프트웨어 개발 방식 자체를 바꿔야 한다는 것이다. 

요약하자면, NVIDIA GPU와 AMD의 MI300X를 비교했을 때, MI300X가 이론적으로는 우위를 가질 가능성이 있었지만, AMD의 공개 소프트웨어 스택의 부족과 테스트 부재로 인해 그 잠재력이 실현되지 못했다. AMD의 소프트웨어 경험은 다수의 버그로 가득 차 있어, AMD를 사용한 기본(out of the box) 학습은 사실상 불가능한 상태이다. 우리는 AMD가 학습 워크로드에서 NVIDIA에 대항할 강력한 경쟁자로 떠오를 수 있기를 기대했지만, 오늘날 기준으로는 유감스럽게도 그렇지 못했다. AMD는 CUDA 생태계의 격차(CUDA moat)를 넘지 못하고 있으며, 이는 AMD의 예상보다 약한 소프트웨어 품질 관리(QA) 문화와 미흡한 초기 사용 경험(out of the box experience) 때문이다.**AMD가 CUDA 격차를 메우기 위해 노력하는 동안, NVIDIA 엔지니어들은 새로운 기능, 라이브러리, 성능 업데이트를 통해 그 격차를 더욱 깊게 만드는 데 주야로 작업하고 있다.**

SemiAnalysis는 GEMM 벤치마크 및 단일 노드 학습에 대한 소스 코드와 중간 테스트 결과를 Nvidia와 AMD 양측에 공유했으며, 피드백을 수집하고 벤치마크를 개선하기 위해 여러 차례 회의와 논의를 진행했다. 또한 AMD와 협력해 소프트웨어 스택의 버그를 수정했다. 이러한 반복적인 상호작용의 목표는, 실제 사용자들이 경험할 법한 결과를 편견 없이 평가하는 테스트를 보장하는 것이었다.

SemiAnalysis는 이 기사를 몇 달 전 공개하려 했으나, AMD 팀과의 추가 협업과 잠재적인 수정 사항을 탐구하기 위해 더 많은 시간을 할애하기로 했다. AMD 소프트웨어 스택 버그로 인해 MI300X의 성능이 제한적으로 보이지 않도록, 가능한 모든 기회를 제공하기 위해 AMD의 소프트웨어 버그를 확인하고 수정하는 데 상당한 시간을 투자했다. 이를 통해 문제만 드러나는 초기 성능 대신, 개선된 성능을 보여줄 수 있도록 했다. 또한, 이 과정에서 얼마나 많은 튜닝 작업과 버그 수정을 거쳤는지도 설명하여 공정한 인상을 줄 수 있도록 했다. 이러한 접근 방식은 사용자들에게 가능한 최고의 투명성을 제공한다고 생각한다.

**SemiAnalysis는 AMD 생태계를 개선하기 위해 기여할 수 있는 모든 방법을 모색했다. SemiAnalysis의 버그 리포트와 테스트 덕분에 AMD 소프트웨어는 상당히 개선되었지만, 여전히 공개 소프트웨어 스택은 부족한 점이 많다.** SemiAnalysis는 많은 벤치마크를 오픈소스로 공개했으며, 이를 재현할 수 있는 한 줄(one-liner) 명령어도 만들어 배포했다.

리사 수와 AMD 리더십이 소프트웨어와 테스트 스택에 대한 투자를 두 배로 늘리고 초점을 맞춘다면, Nvidia와 학습 분야에서 경쟁할 기회를 가질 수 있다. SemiAnalysis는 AMD 엔지니어들이 매우 유능하며, AMD 생태계를 발전시키기 위해 최선을 다하고 있다고 생각한다. 실제로, 이 엔지니어들의 지원(버그 수정, 설정 도움, 커스텀 이미지 제공 등)은 SemiAnalysis가 MI300X에서 더 나은 결과를 얻는 데 큰 도움이 되었다.

벤치마크 프로세스를 마무리하기 위해, 2024년 11월 15일, SemiAnalysis는 Nvidia와 AMD에 GEMM 및 단일 노드 벤치마크 코드와 주요 결과 초안을 전달하며, 의견, 검증 및 튜닝을 요청했다. 최종 의견, 수정, 피드백, 성능 개선 요청 마감일은 11월 25일로 설정했다. 이 시간표는 심층 분석과 논평 작성, 내부 및 외부 리뷰를 여러 차례 진행할 시간을 확보하기 위해 마련된 것으로, 일반적으로 이러한 과정은 2~4주 정도 소요된다.

며칠 전, 기사 12월 20일 공개 예정일을 양측에 알린 후, AMD는 개발자 브랜치의 베타 WIP 개발 빌드를 기반으로 한 결과를 포함하기 위해 공개를 연기해달라고 요청했다. 반면, Nvidia에 대한 모든 벤치마크는 공개적으로 이용 가능한 안정 빌드에서 진행되었다. 투명성과 공정성을 위해, SemiAnalysis는 11월 25일 기준 이미지와 최신 공개 소프트웨어를 기반으로 한 결과를 모두 포함했다. 하지만, 결과를 올바르게 해석하려면 AMD/Nvidia의 안정적 공개 빌드 성능에 초점을 맞추는 것이 적절하다고 본다.

**아래는 우리가 벤치마킹에 사용한 소프트웨어 빌드 목록입니다.각 빌드는 Nvidia와 AMD의 현재와 향후 성능을 비교하고, 특히 AMD의 안정 빌드와 개발 빌드가 제공할 성능 향상을 평가하기 위해 사용되었다:**

	1.	H100 Public Stable Release – Nvidia H100의 기본(out of box) 경험을 제공하는 공개 안정 빌드.
	2.	H200 Public Stable Release – Nvidia H200의 기본 경험을 제공하는 공개 안정 빌드.
	3.	MI300X Nov 25th Custom Build – AMD의 주요 엔지니어들이 제작한 VIP 도커 이미지로, 모든 종속성을 소스 코드에서 직접 빌드.
	4.	MI300X Stable Public Release PyTorch 2.5.1 – AMD MI300X의 기본 경험을 제공하는 공개 안정 빌드.
	5.	MI300X Public Nightly Dec 19th – 2025년 1월 PyTorch 2.6이 출시될 때 예상되는 AMD 성능을 보여주는 공개 나이틀리 빌드.
	6.	MI300X Dec 21st WIP Dev Build – 기사 공개 연기 후 AMD가 제출한 실험적 개발 빌드. 아직 AMD 내부 메인 브랜치에 병합되지 않았으며, PyTorch Flash Attention API를 사용하지 않음. 이 빌드 성능은 향후 1~2분기 내 AMD의 공개 안정 빌드 성능을 예측할 수 있음.

이번 과정에서 AMD와 Nvidia가 제공한 기술 지원에 깊이 감사드리며, SemiAnalysis가 공개하는 결과는 독립적으로 유지하고 있음을 밝힌다. AMD 측에서는 아뉘쉬 엘랑고반(AMD AI 부사장), 후이 류, 그리고 수십 명의 뛰어난 AMD 주요/수석 엔지니어, 엔지니어링 부사장(VP), 펠로우(Fellow), CVP, 디렉터, 소프트웨어 라이브러리 리더들이 우리의 버그 리포트를 신속히 처리하고 수정해 주신 점에 감사를 전한다. 또한, Nvidia 측에서는 케다르 포트다르, 이안 벅, 실뱅 주쥐, 그리고 NCCL 팀에게 훌륭한 지원에 대해 감사드린다. 

추가로, 컴퓨팅 리소스를 제공하고 오픈소스 벤치마킹을 지원해준 [Crusoe](https://crusoe.ai/cloud), [TensorWave(AMD Ventures Portco)](https://tensorwave.com/), [Nebius](https://nebius.com/), [Lambda](https://lambdalabs.com/), [Hot Aisle](https://hotaisle.xyz/), [Sustainable Metal Cloud(SMC)](https://smc.co/) / [Firmus](https://firmus.co/)에도 감사드린다. Crusoe, Nebius, SMC / Firmus, Lambda는 기본적으로 SLURM 관리와 공유 홈 디렉터리를 지원한다. TensorWave는 현재 베타 버전으로 SLURM 관리를 제공하고 있으며, 이 기능은 내년 초에 정식 출시될 예정이다. 특히 Sustainable Metal Cloud는 [공식적으로 MLPerf GPT-3 175B 학습 결과를](https://mlcommons.org/benchmarks/training/) 보유한 몇 안 되는 네오클라우드 중 하나이다. 앞으로 H100, H200, MI300X에 대한 추론 성능 관련 후속 기사를 공개할 예정이다. 또한, 몇 달 뒤에는 AMD 학습 성능과 초기 상태(out of box) 경험이 개선되었는지 확인하고 LlaVa, Mamba와 같은 모델을 테스트하는 후속 기사도 발행할 수 있다.

SemiAnalysis는 H100, H200, MI300X에 대한 추론 성능 관련 후속 기사를 공개할 예정이다. 또한, 몇 달 후에는 AMD 학습 성능을 점검하기 위해 후속 기사를 발행할 수 있으며, 이 과정에서 기본 설정 경험이 개선되었는지 확인하고 LlaVa, Mamba와 같은 다른 모델도 테스트할 예정이다. 

[Source: SemiAnalysis]

### 2. 주요 발견사항 ###

	•	이론적 FLOP/s 및 HBM 대역폭/용량 비교는 단순히 카메라의 화소 수를 비교하는 것과 같다. 실제 성능을 확인하려면 벤치마크를 실행해야 한다.
	•	Nvidia 기본 성능 및 경험은 훌륭하며, 벤치마크 과정에서 Nvidia 소프트웨어 버그를 발견하지 않았다. Nvidia는 기술 지원을 위해 엔지니어 한 명을 배정했지만, 특별한 문제가 없어서 많은 지원이 필요하지 않았다.
	•	AMD 기본 경험은 다루기 어려우며, 사용 가능한 상태로 만들기 위해 상당한 노력과 인내가 필요하다. 대부분의 벤치마크에서 AMD PyTorch 공개 안정 빌드는 여전히 문제가 있으며, 이를 해결하기 위해 우회 방법이 필요했다.
	•	AMD 엔지니어링 팀의 버그 수정 지원이 없었다면, AMD의 결과는 Nvidia보다 훨씬 낮았을 것이다.
	•	SemiAnalysis는 Sustainable Metal Cloud와 협력해 256 H100으로 비공식 MLPerf GPT-3 175B 학습을 실행하며 VBoost 설정의 효과를 테스트했다.
	•	AMD 공개 안정 빌드 소프트웨어에서의 실제 성능은 광고된 TFLOP/s와 거리가 멀다. Nvidia도 마찬가지로 실제 성능이 광고된 TFLOP/s에 미치지 못하지만, 차이가 AMD만큼 크지 않다.
	•	MI300X는 H100/H200 대비 총 소유 비용(TCO)이 낮지만, TCO 대비 학습 성능은 AMD 소프트웨어 안정 빌드 기준으로 더 낮다. 단, AMD 커스텀 개발 빌드를 사용하면 이 결과는 달라진다.
	•	MI300X의 학습 성능은 AMD의 행렬 곱셈 벤치마크에서 약점이 드러났으며, 단일 노드 학습 처리량은 여전히 Nvidia H100/H200에 뒤처진다.
	•	AMD 소프트웨어의 BF16 개발 브랜치는 성능이 더 좋지만, 아직 메인 브랜치에 병합되지 않았으며, PyTorch 안정 빌드에 통합되기까지 시간이 걸린다. 이때쯤이면 Nvidia Blackwell이 이미 출시될 것이다.
	•	MI300X는 AMD의 약한 ROCm Compute Communication Library(RCCL)와 네트워킹 및 스위칭 하드웨어에 대한 수직 통합 부족으로 인해 스케일 아웃 성능이 약하다. 반면 Nvidia는 NCCL, InfiniBand/Spectrum-X 네트워크 패브릭 및 스위치를 통해 강력한 통합을 보인다.
	•	AMD AI 라이브러리의 상당수는 Nvidia AI 라이브러리를 포크(fork)한 것으로, 최적의 결과를 내지 못하거나 호환성 문제를 초래한다.
	•	AMD 고객들은 주로 추론에 대해 수작업으로 설계된 커널만 사용하며, 이는 정의된 좁은 사용 사례 외 성능이 낮고, 급변하는 워크로드에 유연성이 거의 없다.

 ### 3. ###

 
