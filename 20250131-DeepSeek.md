# DeepSeek 논쟁: 전체 비용, 실제 훈련 및 폐쇄 모델 마진 영향 측면에서 본 중국 리더쉽 #

## 전체 요약: H100 가격 급등, 보조금 지원 추론 가격, 수출 통제, MLA ##

### 1. 전 세계를 강타한 DeepSeek ### 

지난 한 주 동안, DeepSeek은 전 세계적으로 가장 뜨거운 화제가 되었다. 현재 DeepSeek의 일일 트래픽은 Claude, Perplexity, 심지어 Gemini보다도 훨씬 높은 수준에 도달했다. 그러나 AI 업계를 면밀히 관찰해 온 사람들에게 이는 완전히 새로운 소식은 아니다. [SemiAnalysis는](https://x.com/dylan522p/status/1819431961368129554?mx=2) 이미 몇 달 전부터 [DeepSeek에 대해](https://x.com/dylan522p/status/1859302712803807696) [논의해](https://x.com/dylan522p/status/1875594509339521414) [왔다.](https://semianalysis.com/2024/05/07/openai-is-doomed-et-tu-microsoft/) DeepSeek 자체는 새로운 기업이 아니지만, 현재의 광적인 열풍은 분명 새롭다. 
SemiAnalysis는 오랫동안 DeepSeek이 매우 뛰어난 기술력을 보유하고 있음에도 불구하고, 미국의 대중은 이에 대해 큰 관심을 보이지 않았다고 주장해 왔다. 하지만 이제 세계가 DeepSeek에 주목하기 시작하자, 현실을 제대로 반영하지 못하는 과장된 열풍이 형성되었다. SemiAnalysis는 한 달 전과 비교해 완전히 뒤바뀐 내러티브를 강조하고 싶다. 당시에는 스케일링 법칙이 깨졌다는 주장이 나왔지만, 우리는 이 신화를 불식시켰다.(*) 이제는 알고리즘 개선 속도가 지나치게 빠르다는 우려가 나오며, 이것이 NVIDIA 및 GPU 산업에 부정적인 영향을 미칠 수도 있다는 의견까지 제기되고 있다. 
현재 내러티브는 DeepSeek이 너무 효율적이어서 더 많은 컴퓨팅 자원이 필요하지 않으며, 모델의 변화로 인해 모든 인프라가 과잉 용량 상태에 놓였다는 것이다. 그러나 Jevons 역설 역시 과장된 측면이 있지만, 현실에 더 가까운 것은 Jevons 역설이다. 이미 모델들은 실제 수요를 유발했으며, 이는 H100과 H200의 가격에 가시적인 영향을 미치고 있다. 

### 2. DeepSeek 과 High-Flyer의 관계 ###

High-Flyer는 중국의 헤지펀드로, 트레이딩 알고리즘에 AI를 조기에 도입한 선구적인 기업이다. 이들은 AI가 금융 분야뿐만 아니라 다양한 산업에서 지닌 잠재력을 일찍이 인식했으며, 스케일링(Scaling)의 중요성을 간파했다. 그 결과, 지속적으로 GPU 공급을 확대해 왔다.
수천 개의 GPU 클러스터를 활용한 모델 실험을 거친 후, High-Flyer는 2021년 수출 제한이 적용되기 전에 10,000개의 A100 GPU에 투자했다. 이 결정은 큰 성과를 거두었다.
High-Flyer가 기술을 발전시켜 나가면서, 보다 집중적으로 AI 역량을 강화할 필요성을 느끼게 되었다. 이에 따라 2023년 5월, "DeepSeek"을 스핀오프(분사) 하기로 결정했다. DeepSeek은 AI 연구 및 개발에 보다 집중하기 위한 목적으로 설립되었다.
당시 AI 관련 비즈니스 모델의 부재로 인해 외부 투자자들의 관심이 크지 않았으나, High-Flyer는 자체 자금으로 DeepSeek을 지원했다. 현재 High-Flyer와 DeepSeek은 인적 및 컴퓨팅 자원을 공동으로 활용하며 긴밀히 협력하고 있다.
DeepSeek은 이제 진지하고 체계적인 노력을 기울이는 대규모 프로젝트로 성장했으며, 일부 언론에서 주장하는 것처럼 결코 단순한 "사이드 프로젝트"가 아니다. 우리는 수출 통제 조치를 고려하더라도, DeepSeek이 GPU 투자에 5억 달러(미화) 이상을 지출했을 가능성이 높다고 확신하고 있다.

### 3. 현재 GPU 상황 ###

SemiAnalysis는 해당 기관이 약 50,000개의 Hopper GPU에 접근할 수 있다고 보고 있다. 이는 일부에서 주장하는 50,000개의 H100과는 다르다. NVIDIA는 다양한 규제를 준수하기 위해 H100의 여러 변종(예: H800, H20)을 제작했으며, 현재 중국 모델 제공자에게는 H20만이 제공되고 있다. 참고로 H800은 H100과 동일한 계산 성능을 갖추고 있지만, 네트워크 대역폭은 더 낮다.
DeepSeek는 약 10,000개의 H800과 10,000개의 H100에 접근할 수 있는 것으로 보인다. 또한, DeepSeek는 추가로 많은 H20에 대한 주문을 보유하고 있으며, NVIDIA는 지난 9개월 동안 중국 전용 GPU를 100만 개 이상 생산한 것으로 알려져 있다. 이 GPU들은 High-Flyer와 DeepSeek 간에 공유되며, 어느 정도 지리적으로 분산되어 사용되고 있다. 이들은 트레이딩, 추론, 학습, 연구 등 다양한 용도로 활용되고 있다. 보다 구체적이고 상세한 분석은 해당 기업의 [Accelerator Model을](https://semianalysis.com/accelerator-industry-model/) 통해 확인할 수 있다.
SemiAnalysis 분석에 따르면, DeepSeek의 전체 서버 자본 지출(CapEx)은 약 16억 달러에 달하며, 이 클러스터를 운영하는 데 드는 비용은 약 9억 4,400만 달러로 상당한 규모를 자랑한다. 마찬가지로, 모든 AI 연구소와 Hyperscaler들은 자원 중앙화가 어려워 개별 훈련 작업에 할당하는 것보다 다양한 작업을 위해 훨씬 더 많은 GPU를 보유하고 있다. X.AI는 모든 GPU가 하나의 장소에 모여 있는 독특한 AI 연구소이다.
DeepSeek은 인재를 중국에서만 채용하며, 이전 경력에 관계없이 능력과 호기심을 중요하게 여긴다. DeepSeek은 북경대(PKU)와 절강대(Zhejiang)와 같은 명문 대학에서 채용 행사를 자주 개최하며, 이곳에서 많은 직원들을 뽑았다. 직원의 역할은 반드시 사전 정의되어 있지 않으며, 채용된 사람들에게는 유연성이 주어지며, 구인 광고에는 사용 제한 없는 10,000개 이상의 GPU에 접근할 수 있다는 내용도 포함되어 있다. 이들은 매우 경쟁력이 있으며, 유망한 후보자에게 130만 달러 이상의 연봉을 제안한다고 전해지며, 이는 Moonshot과 같은 다른 대형 중국 기술 기업 및 AI 연구소보다 훨씬 높은 금액이다. 현재 직원 수는 약 150명이며, 빠르게 성장하고 있다.
역사적으로 볼 때, 자금이 잘 지원된 작은 스타트업이 종종 가능한 한계를 뛰어넘을 수 있다. DeepSeek은 구글과 같은 대기업의 관료주의가 없고, 자체 자금으로 운영되기 때문에 아이디어를 빠르게 실현할 수 있다. 그러나 구글처럼 DeepSeek도 대부분 자체 데이터 센터를 운영하며, 외부 파트너나 협력 업체에 의존하지 않는다. 이는 실험을 위한 더 많은 기회를 제공하고, 전체 스택에서 혁신을 이룰 수 있게 한다. SemiAnalysis는 DeepSeek가 오늘날 "공개 가중치(Open Weight)" 연구소 중 가장 우수하다고 믿으며, Meta의 Llama, Mistral 등 다른 경쟁자를 능가한다고 평가한다.

### 4. DeepSeek의 비용과 성능 ###

DeepSeek의 가격과 효율성은 이번 주에 큰 관심을 끌었으며, 주요 헤드라인은 DeepSeek V3의 “600만 달러” 훈련 비용이었다. 이는 잘못된 정보다. 이는 제품의 자재 목록에서 특정 부분을 지적하고 그것을 전체 비용으로 잘못 해석하는 것과 같다. 사전 훈련 비용은 전체 비용에서 매우 작은 부분에 해당한다.

### 4-1. 훈련 비용 ###
SemiAnalysis는 사전 훈련에 사용된 숫자가 모델에 실제로 지출된 총 비용이라고 보지 않는다. 회사 역사 전체를 통틀어 하드웨어에 지출된 비용은 5억 달러 이상일 것이라고 확신한다. 새로운 아키텍처 혁신을 개발하기 위해, 모델 개발 과정에서는 새로운 아이디어와 아키텍처, 그리고 ablation 실험  등에 상당한 비용이 소요된다. DeepSeek의 주요 혁신 중 하나인 Multi-Head Latent Attention 은 개발하는 데 몇 달이 걸렸으며, 한 팀의 인력 시간과 GPU 사용 시간이 모두 소요되었다.

논문에 언급된 600만 달러 비용은 사전 훈련 실행에서 발생한 GPU 비용에 불과하며, 이는 모델 전체 비용의 일부에 불과하다. 여기에는 R&D 비용과 하드웨어 자체의 총 소유 비용(TCO) 등 중요한 부분들이 제외되어 있다. 참고로, Claude 3.5 Sonnet의 훈련 비용은 수천만 달러에 달했으며, 만약 그 비용이 Anthropic이 필요로 하는 전체 비용이었다면, 구글로부터 수십억 달러, 아마존으로부터 수백억 달러를 모금하지 않았을 것이다. 이는 그들이 실험, 새로운 아키텍처 개발, 데이터 수집 및 정제, 직원 급여 지급 등 다양한 추가 비용을 감안해야 하기 때문이다. 그렇다면, DeepSeek이 어떻게 이렇게 대규모 클러스터를 보유할 수 있었을까? 수출 통제의 지연이 그 핵심이며, 이에 대해서는 아래의 수출 섹션에서 다룰 예정이다.

        * Ablation 실험: 모델이나 시스템의 특정 구성 요소를 하나씩 제거하거나 변경해 보면서, 그 요소가 전체 성능이나 결과에 미치는 영향을 분석하는 실험 방법을 말한다. 이를 통해 각 요소의 기여도를 파악하고, 어떤 부분이 모델의 성능에 중요한지 또는 불필요한지를 평가할 수 있다.

        * Multi-Head Latent Attention은 DeepSeek가 개발한 주요 혁신 중 하나로, 일반적인 Transformer의 Multi-Head Attention 개념을 확장하거나 변형한 형태임. 기본적으로 Multi-Head Attention은 입력의 여러 부분 간의 상호관계를 동시에 여러 ‘어텐션 헤드’를 통해 학습하여, 다양한 특징을 동시에 포착하는 역할을 한다. 여기서 "Latent"라는 단어가 추가된 것은, 어텐션 계산이 단순히 입력 토큰 간의 관계뿐만 아니라, 모델의 잠재 공간(latent space)에서 추출된 은닉 표현들 간의 관계에도 초점을 맞춘다는 의미로 해석할 수 있다. 즉, Multi-Head Latent Attention은 모델 내부의 잠재적 특징들을 여러 어텐션 헤드를 통해 병렬로 분석함으로써, 다양한 관점에서 데이터를 해석하고 보다 풍부한 정보를 학습할 수 있도록 도와주는 기법이다.

### 4.2 DeepSeek V3의 성능 – o1과 격차 해소 ###   

V3는 의심할 여지없이 인상적인 모델이지만, “인상적”이라는 표현이 무엇과 비교할 때 인상적인지를 강조할 필요가 있다. 많은 사람들이 V3를 GPT-4o와 비교하며 V3가 4o보다 우수한 성능을 보인다고 강조한다. 이는 사실이지만, GPT-4o는 2024년 5월에 출시되었다. AI는 빠르게 발전하며, 2024년 5월은 알고리즘 개선 측면에서 이미 오래 전의 일이 되었다. 게다가 일정 시간이 지난 후 비슷하거나 더 강력한 능력을 적은 계산 자원으로 달성하는 것은 놀라운 일이 아니다. 추론 비용의 급감은 AI 발전의 대표적인 특징이다.

V3는 의심할 여지없이 인상적인 모델이지만, “인상적”이라는 표현이 무엇과 비교할 때 인상적인지를 강조할 필요가 있다. 많은 사람들이 V3를 GPT-4o와 비교하며 V3가 4o보다 우수한 성능을 보인다고 강조한다. 이는 사실이지만, GPT-4o는 2024년 5월에 출시되었다. AI는 빠르게 발전하며, 2024년 5월은 알고리즘 개선 측면에서 이미 오래 전의 일이 되었다. 게다가 일정 시간이 지난 후 비슷하거나 더 강력한 능력을 적은 계산 자원으로 달성하는 것은 놀라운 일이 아니다. 추론 비용의 급감은 AI 발전의 대표적인 특징이다.

지금까지 이러한 패턴에서 SemiAnalysis가 목격한 바에 따르면, AI 연구소들은 투자하는 비용 대비 더 높은 지능을 얻기 위해 절대적인 금액을 더 많이 지출하고 있다. 알고리즘 발전은 연간 4배의 향상을 보인다는 추정이 있으며, 이는 매년 동일한 성능을 달성하기 위해 필요한 계산량이 4배 줄어든다는 의미이다. Anthropic의 CEO인 Dario는 알고리즘 발전 속도가 더 빠르며 10배의 개선 효과를 가져올 수 있다고 주장한다. GPT-3 수준의 추론 비용에 관해서는 비용이 1,200배 감소했다.

GPT-4의 비용을 조사해 보면, 비용 감소가 유사하게 나타나지만 그래프 상 초반부에서의 변화로 설명할 수 있다. 이 경우, 알고리즘 개선과 최적화 덕분에 비용이 10배 감소하고 성능은 향상되는 결과를 보이고 있다.

분명히 말하자면, DeepSeek은 이 정도의 비용과 성능을 처음으로 달성했다는 점에서 독보적이다. 그들이 공개 가중치(Open Weight)를 공개한 점 또한 독특하지만, 이전의 Mistral과 Llama 모델들도 과거에 이런 사례를 보여주었다. DeepSeek은 이 정도의 비용 수준을 달성했으나, 연말까지 비용이 또 5배 더 하락하더라도 놀라지 말아야 한다.




