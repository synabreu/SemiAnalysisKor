### 스케일링 법칙 ###

##### 최근 AI 스케일링 법칙에 대해 두려움(Fear), 불확실성(Uncertainty), 의심(Doubt), 즉 FUD가 점점 커지고 있다. 파트타임 AI 산업 전망가들의 무리(“칼러베이드”)가 어떤 비관적 서사라도 붙잡고 늘어지며, 지난 몇 년간 대형 언어 모델(LLM)의 급속한 성능 향상을 이끌어온 스케일링 법칙의 종말을 선언하고 있다. 기자들 역시 이러한 집단 비난에 가세하고 있는데, 이들은 모호한 정보로 가득한 시끄러운 유출 자료들에 의존해, 모델이 예전만큼 성공적으로 스케일하지 못하는 “실패” 사례를 근거로 제시한다. 또 다른 회의론자들은 이미 포화된 벤치마크를 들며, 최신 모델들이 해당 벤치마크에서 개선의 기미를 거의 보이지 않는다는 점을 지적한다. 비평가들은 또한 이용 가능한 학습 데이터의 고갈과 학습용 하드웨어 스케일링 둔화를 문제로 삼는다. #####

